{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shell matrices and memory usage in `dynamite`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demonstration, we'll use the long-range XX+Z model we saw last time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamite.operators import sigmax, sigmaz, index_sum, op_sum\n",
    "\n",
    "# the None default argument will be important later\n",
    "def build_hamiltonian(L):\n",
    "    interaction = op_sum(index_sum(sigmax(0)*sigmax(i), size=L) for i in range(1,L))\n",
    "    uniform_field = 0.5*index_sum(sigmaz(), size=L)\n",
    "    return interaction + uniform_field\n",
    "\n",
    "# look at an example\n",
    "build_hamiltonian(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the structure of the matrix. `dynamite` uses sparse linear algebra, meaning that only nonzero matrix elements are stored. But the high connectivity of this model means that there are a good number of nonzero matrix elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "H = build_hamiltonian(8)\n",
    "H.spy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a graphic representation of our matrix, where each black dot is a nonzero element. As we can see, the matrix is quite dense. We can quantitatively asses the density. For a Hamiltonian of size 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = build_hamiltonian(20)\n",
    "\n",
    "print('nonzeros per row:          ', H.nnz)\n",
    "print('matrix dimension:          ', H.dim)\n",
    "print('total nonzeros (nnz*nrows):', H.nnz*H.dim[0])\n",
    "print('density (nnz/dim):         ', H.density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That total number of nonzeros we need to store is a pretty big number. Let's look at our memory usage for a system of size 18:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamite.tools import get_cur_memory_usage\n",
    "from timeit import timeit\n",
    "\n",
    "H = build_hamiltonian(18)\n",
    "\n",
    "before = get_cur_memory_usage()\n",
    "duration = timeit(H.build_mat, number=1, globals=globals())\n",
    "after = get_cur_memory_usage()\n",
    "\n",
    "print('matrix memory usage: %f Mb' % ((after-before)/1E6))\n",
    "print('matrix build time: %f s' % duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't even a very large number of particles, and the memory usage is already almost a gigabyte. Also, building the matrix is time consuming. Fortunately, dynamite has built-in \"matrix-free\" methods, which compute matrix elements on-the-fly when needed, and never store them. Let's see the memory usage for a shell matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H.shell = True\n",
    "\n",
    "before = get_cur_memory_usage()\n",
    "duration = timeit(H.build_mat, number=1, globals=globals())\n",
    "after = get_cur_memory_usage()\n",
    "\n",
    "print('matrix memory usage: %f Mb' % ((after-before)/1E6))\n",
    "print('matrix build time: %f s' % duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extra memory usage is obviously not zero. But it is small enough that it doesn't even get noticed by the memory tracker. And the matrix build time is almost nothing! That's because nothing is really being \"built\"---the matrix elements are computed on the fly when needed.\n",
    "\n",
    "One might think that generating the matrix elements on the fly would incur a speed penalty. Let's compare the performance for a matrix-vector multiplication: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_noshell = H.copy()\n",
    "H_noshell.shell = False\n",
    "H_noshell.build_mat() # so we aren't counting this in the matrix-vector multiply time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamite.states import State\n",
    "\n",
    "# get states compatible with this operator\n",
    "state, result = H.create_states()\n",
    "\n",
    "no_shell_t = timeit(\"H_noshell.dot(state, result)\", number=1, globals=globals())\n",
    "shell_t = timeit(\"H.dot(state, result)\", number=1, globals=globals())\n",
    "\n",
    "print('Non-shell mat-vec multiply time: %f s' % no_shell_t)\n",
    "print('Shell mat-vec multiply time:     %f s' % shell_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is almost the same. Shell matrices do more work to compute the matrix elements on the fly, but they avoid memory bandwidth problems of storing the elements explicitly. Depending on the Hamiltonian's structure, the speed will vary, but they will always use much less memory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
